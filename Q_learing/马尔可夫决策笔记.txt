随机过程：研究对象是随时间演变的随机现象。随机现象在某时刻t的取值是一个向量随机变量
马尔可夫性质：当且仅当某时刻的状态只取决于上一时刻的状态时，一个随机过程被称为具有马尔可夫性质
马尔可夫过程：具有马尔可夫性质的随机过程
状态转移矩阵：定义了所有状态对之间的转移概率

马尔可夫奖励过程：
        在马尔可夫过程的基础上加入奖励函数 r 和折扣因子 γ
        奖励过程由（S，P，r，γ）：
                S：有限状态的集合
                P：状态转移矩阵
                r：奖励函数，某状态s的奖励r（s）指转移到该状态时可以获得奖励的期望
                γ：折扣因子，【0，1】。引入折扣因子的理由为远期利益具有一定不确定性，有时候我们更希望能够尽快获得一些奖励，所以我们需要对
                        远期利益打折。接近1的γ更关注长期的累计奖励，接近0则更考虑短期奖励

        回报Gt：
                从第t时刻状态St开始，直至终止状态时，所有奖励的衰减之和称为回报，衰减为γ

        价值函数Vs：
                一个状态的期望回报（即从这个状态出发的未来累积奖励的期望）被称为这个状态的价值，所有状态的价值组成价值函数
                输入为某个状态，输出为这个状态的价值，V（s）= E【Gt | St=s】= E【Rt+γV（St+1） | St=s】
                可推导出非常有名的贝尔曼方程

                        价值函数V=【V（s1），V（s2），。。。，V（sn）】T
                        奖励函数R=【r（s1），r（s2），。。。，r（sn）】T
                        则 V = R + γPV = （I - γP）（-1）R
                                公式计算只适合很小的马尔可夫奖励过程
                                求解较大规模的马尔可夫奖励过程中的价值函数时，可以使用动态规划、蒙特卡洛和时序差分

马尔可夫决策过程：
